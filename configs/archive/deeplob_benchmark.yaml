# DeepLOB Benchmark Configuration Template (ARCHIVED)
#
# STATUS: ARCHIVED - Uses legacy nvda_balanced dataset (165 days)
# For current experiments, use nvda_11month_complete (234 days) with TLOB model.
#
# VALUE: Reference for DeepLOB model configuration (Zhang et al. 2019)
#
# This is the BASE TEMPLATE for DeepLOB experiments.
#
# Reference:
#   Zhang, Zohren & Roberts (2019). "DeepLOB: Deep Convolutional Neural 
#   Networks for Limit Order Books." IEEE Trans. Signal Processing.
#
# Usage:
#   python scripts/train.py --config configs/archive/deeplob_benchmark.yaml
#
# =============================================================================
# HORIZON INDEX MAPPING (nvda_balanced dataset)
# =============================================================================
# The dataset contains labels for 5 prediction horizons:
#
#   horizon_idx: 0  →  h=10   (~1 second ahead)    - easiest, best class balance
#   horizon_idx: 1  →  h=20   (~2 seconds ahead)
#   horizon_idx: 2  →  h=50   (~5 seconds ahead)
#   horizon_idx: 3  →  h=100  (~10 seconds ahead)  - PAPER BENCHMARK
#   horizon_idx: 4  →  h=200  (~20 seconds ahead)  - hardest, worst class balance
#
# IMPORTANT: The original DeepLOB paper uses k=4 which corresponds to h=100.
#            Use horizon_idx=3 (not 4!) for paper comparison.
# =============================================================================

name: deeplob_benchmark_nvda
description: |
  DeepLOB benchmark template for NVDA price direction prediction.
  
  Architecture (exact paper spec):
  - 3 Conv blocks (32 filters each)
  - Inception module (64 filters per branch, 192 total)
  - LSTM (64 hidden units)
  - Linear classifier (3 classes)
  
  Data contract:
  - Input: First 40 LOB features in GROUPED layout
    [ask_prices(10), ask_sizes(10), bid_prices(10), bid_sizes(10)]
  - DeepLOB internally rearranges to FI2010 layout for CNN processing
  - Sequences: [N_seq, 100, 40] after feature selection

tags:
  - deeplob
  - benchmark
  - nvda
  - template
  - archived

# =============================================================================
# Data Configuration
# =============================================================================
data:
  data_dir: "../data/exports/nvda_balanced"
  feature_count: 98  # Full dataset has 98, benchmark uses first 40
  
  # ⚠️ MODIFY THIS for different horizons (see mapping above)
  horizon_idx: 0  # Default: h=10 (quickest results, best class balance)
  
  sequence:
    window_size: 100  # Must match Rust export config
    stride: 10
  
  normalization:
    strategy: zscore_per_day
    eps: 1.0e-8
    clip_value: 10.0
    exclude_features: []
  
  label_encoding: categorical
  num_classes: 3
  cache_in_memory: true

# =============================================================================
# Model Configuration - DeepLOB (Zhang et al. 2019)
# =============================================================================
model:
  model_type: deeplob
  
  # DeepLOB-specific parameters (paper defaults)
  deeplob_mode: benchmark  # Use exact paper architecture
  deeplob_conv_filters: 32  # Paper: 32 filters per conv block
  deeplob_inception_filters: 64  # Paper: 64 filters per inception branch
  deeplob_lstm_hidden: 64  # Paper: 64 hidden units
  deeplob_num_levels: 10  # 10 LOB levels (standard)
  
  # Schema-required fields (not used for DeepLOB)
  input_size: 40
  hidden_size: 64
  num_layers: 1
  dropout: 0.0
  num_classes: 3

# =============================================================================
# Training Configuration
# =============================================================================
train:
  batch_size: 64
  learning_rate: 1.0e-4  # Conservative for NVDA data
  weight_decay: 0.0
  
  # Quick iteration settings (adjust as needed)
  epochs: 10  # Start small, increase if promising
  early_stopping_patience: 5
  
  gradient_clip_norm: 1.0
  scheduler: cosine
  num_workers: 0  # Required for macOS
  pin_memory: true
  seed: 42
  mixed_precision: false
  use_class_weights: false

# =============================================================================
# Output
# =============================================================================
output_dir: outputs/deeplob_benchmark
log_level: INFO
